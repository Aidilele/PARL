[33m[11-16 14:34:28 MainThread @tensorboard.py:32][0m [5m[33mWRN[0m [tensorboard] logdir is None, will save tensorboard files to train_log/train
View the data using: tensorboard --logdir=train_log/train --host=10.90.243.39
[32m[11-16 14:35:50 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 2016, 'sample_total_steps': 2016000, 'evaluate_rewards_mean': 307.3045187085081, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:37:09 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 3024, 'sample_total_steps': 3024000, 'evaluate_rewards_mean': 723.7031396576125, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:38:33 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 4032, 'sample_total_steps': 4032000, 'evaluate_rewards_mean': 644.6498672452354, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:39:53 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 5040, 'sample_total_steps': 5040000, 'evaluate_rewards_mean': 644.6498672452354, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:41:13 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 6048, 'sample_total_steps': 6048000, 'evaluate_rewards_mean': 889.8160228556751, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:42:31 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 7056, 'sample_total_steps': 7056000, 'evaluate_rewards_mean': 889.8160228556751, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:43:49 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 8064, 'sample_total_steps': 8064000, 'evaluate_rewards_mean': 889.8160228556751, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:45:08 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 9072, 'sample_total_steps': 9072000, 'evaluate_rewards_mean': 1250.2884124117372, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:46:27 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 10080, 'sample_total_steps': 10080000, 'evaluate_rewards_mean': 1508.398401191186, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:47:48 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 11088, 'sample_total_steps': 11088000, 'evaluate_rewards_mean': 1706.6956156590336, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:49:07 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 12096, 'sample_total_steps': 12096000, 'evaluate_rewards_mean': 1879.4959785471478, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:50:26 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 13104, 'sample_total_steps': 13104000, 'evaluate_rewards_mean': 1879.4959785471478, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
[32m[11-16 14:51:46 MainThread @train.py:174][0m {'episodes_this_iter': 1008, 'sample_total_episodes': 14112, 'sample_total_steps': 14112000, 'evaluate_rewards_mean': 1879.4959785471478, 'evaluate_steps_mean': 1000.0, 'timesteps_this_iter': 1008000}
